{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a994a9",
   "metadata": {},
   "source": [
    "# Session 5: Data munging with Pandas - Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e48b34",
   "metadata": {},
   "source": [
    "## [EAA - ARC Python Primer for Accounting Research](https://martien.netlify.app/book/example/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c56e4c9",
   "metadata": {},
   "source": [
    "### Using Pandas to explore, manage, clean data, deal with missing observations of US bank holding companies.\n",
    "## Assignment\n",
    "---\n",
    "\n",
    "This assignment requires you to munge and explore accounting data of U.S. Bank Holding Companies. The reason I chose this data is that it offers freely available and highly structured accounting data, with a long history, comprising many banks.\n",
    "\n",
    "The main source of data is the [Financial Data Download section](https://www.ffiec.gov/npw/FinancialReport/FinancialDataDownload?selectedyear=2020) of the [National Information Center](https://www.ffiec.gov/npw).\n",
    "\n",
    "Individual Consolidated Financial Statements for Holding Companies on form *FR Y-9C*  can be downloaded via this [link](https://www.ffiec.gov/npw/).\n",
    "\n",
    "For documentation  of the form *FR Y-9C*, see this [link](https://www.federalreserve.gov/apps/reportforms/reporthistory.aspx?sOoYJ+5BzDal8cbqnRxZRg==).\n",
    "\n",
    "I encourage you to download an *FR Y-9C* copy, say, from Citigroup, via this [link](https://www.ffiec.gov/npw/Institution/Profile/1951350?dt=20170701). This enables you to quickly understand the variable names. \n",
    "\n",
    "The [Micro Data Reference Manual](https://www.federalreserve.gov/apps/mdrm/) gives you comprehensive dictionary of the variables used. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d160432b",
   "metadata": {},
   "source": [
    "**Required**:\n",
    "\n",
    "From the FIC website, **download the BHC data** for [2019](https://www.ffiec.gov/npw/FinancialReport/FinancialDataDownload?selectedyear=2019),  [2020](https://www.ffiec.gov/npw/FinancialReport/FinancialDataDownload?selectedyear=2020), and  [2021](https://www.ffiec.gov/npw/FinancialReport/FinancialDataDownload?selectedyear=2021). \n",
    "\n",
    "**Save** the files to a folder on your drive, e.g. `D:/users/my_user_name_here/EAA_python/code/`. The files are zip- compressed `BHCF20200331.ZIP`, `BHCF20211231.ZIP` - **but there is no need to extract the contents of the zip files**. Pandas will do that for you.\n",
    "\n",
    "Run the cells below after setting the correct source folder of your files, i.e. replace `my_user_name_here` with something that works on your machine. See this [link](https://www.youtube.com/watch?v=hUW5MEKDtMM) and this [link](https://www.youtube.com/watch?v=7ABkcHLdG_A) for explanations of folders and directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The usual preamble\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "if os.name=='nt':  # for Windows users\n",
    "    os.chdir('D:/users/my_user_name_here/EAA_python/data/')  # note the forward slashes, change 'martien' to your user name\n",
    "else:\n",
    "    os.chdir('/home/martien/EAA_python/data/')  # For Linux or Mac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371dfa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data file and append them into one large data frame:\n",
    "\n",
    "def load_bhc_data():\n",
    "    df = pd.DataFrame()\n",
    "    for fname in glob.glob('BHCF*.ZIP'):\n",
    "        print(fname)\n",
    "        df = df.append(pd.read_csv(fname, sep='^', encoding=\"ISO-8859-1\", low_memory=False))\n",
    "    print(f'\\nDone!\\n\\nTotal rows in data frame {len(df)}')\n",
    "    print(f'\\nTotal columns in data frame {len(list(df))}\\nThat is a lot!')\n",
    "    return df\n",
    "\n",
    "df = load_bhc_data()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2c3a48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Required**: Use `.value_counts().sort_index()` to check how many observations per quarter your data has. Check this for the column `df['RSSD9999']` only.  \n",
    "\n",
    "Follow this [link]((https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.value_counts.html)) for the correct syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db27bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSSD9999'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d962b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Selecting variables**\n",
    "\n",
    "---\n",
    "Use your knowledge from [Session 3](https://github.com/blucap/EEA_Python_Primer/blob/master/session3.ipynb) and [Session 5](https://github.com/blucap/EEA_Python_Primer/blob/master/session5.ipynb) to keep the variables mentioned in the cell below.\n",
    "\n",
    "**Hint**: use the text from cell below to make a dictionary (name that dictionary `mdrm`) and extract the keys from that dictionary (see [Session 3](https://github.com/blucap/EEA_Python_Primer/blob/master/session3.ipynb)) to make a list called  `var_list`. Use that list to create a new data frame with the relevant variables:  `dfb`: `df = df[var_list].copy()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca1d29a",
   "metadata": {},
   "source": [
    "` 'RSSD9999': 'REPORTING DATE',\n",
    " 'RSSD9001': 'Borrower RSSD ID',\n",
    " 'RSSD9010': 'Entity Short Name',\n",
    " 'RSSD9200': 'Abbreviated State Name',\n",
    " 'RSSD4087': \"Entity's World Wide Web Address\",\n",
    " 'BHCAP793': 'Common Equity Tier 1 Capital Ratio',\n",
    " 'BHCKB529': 'Loans and Leases, Net of Unearned Income and Allowance',\n",
    " 'BHCKB528': 'Loans and Leases, Net of Unearned Income - Totals',\n",
    " 'BHCAA223': 'Risk-Weighted Assets (Net of Allowances and Other Deductions)',\n",
    " 'BHCA8274': 'Tier 1 Capital Allowable Under the Risk-Based Capital Guidelines',\n",
    " 'BHCA7206': 'Tier 1 Risk-Based Capital Ratio',\n",
    " 'BHCA7204': 'Tier 1 Leverage Capital Ratio',\n",
    " 'BHCA7205': 'Total Risk-Based Capital Ratio',\n",
    " 'BHCK5369': 'Loans and Leases Held for Sale',\n",
    " 'BHCK4635': 'Charge-Offs on Allowance for Loan and Lease Losses',\n",
    " 'BHCK4605': 'Recoveries on Allowance for Loan and Lease Losses',\n",
    " 'BHCK3210': 'Total Equity Capital',\n",
    " 'BHCK3123': 'Allowance for Loan and Lease Losses',\n",
    " 'BHCK2170': 'Total Assets',\n",
    " 'BHCK1773': 'Available-for-Sale Debt Securities (From Schedule RC-B, Column D)',\n",
    " 'BHCK0397': 'Interest-Bearing Balances in Foreign Offices, Edge and Agreement Subsidiaries and Ibfs',\n",
    " 'BHCK0395': 'Interest-Bearing Balances in U.S. Offices',\n",
    " 'BHCK0081': 'Noninterest-Bearing Balances and Currency and Coin'\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d65914",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdrm = {\n",
    " 'RSSD9999': 'REPORTING DATE',\n",
    " 'RSSD9001': 'Borrower RSSD ID',\n",
    " 'RSSD9010': 'Entity Short Name',\n",
    " 'RSSD9200': 'Abbreviated State Name',\n",
    " 'RSSD4087': \"Entity's World Wide Web Address\",\n",
    " 'BHCAP793': 'Common Equity Tier 1 Capital Ratio',\n",
    " 'BHCKB529': 'Loans and Leases, Net of Unearned Income and Allowance',\n",
    " 'BHCKB528': 'Loans and Leases, Net of Unearned Income - Totals',\n",
    " 'BHCAA223': 'Risk-Weighted Assets (Net of Allowances and Other Deductions)',\n",
    " 'BHCA8274': 'Tier 1 Capital Allowable Under the Risk-Based Capital Guidelines',\n",
    " 'BHCA7206': 'Tier 1 Risk-Based Capital Ratio',\n",
    " 'BHCA7204': 'Tier 1 Leverage Capital Ratio',\n",
    " 'BHCA7205': 'Total Risk-Based Capital Ratio',\n",
    " 'BHCK5369': 'Loans and Leases Held for Sale',\n",
    " 'BHCK4635': 'Charge-Offs on Allowance for Loan and Lease Losses',\n",
    " 'BHCK4605': 'Recoveries on Allowance for Loan and Lease Losses',\n",
    " 'BHCK3210': 'Total Equity Capital',\n",
    " 'BHCK3123': 'Allowance for Loan and Lease Losses',\n",
    " 'BHCK2170': 'Total Assets',\n",
    " 'BHCK1773': 'Available-for-Sale Debt Securities (From Schedule RC-B, Column D)',\n",
    " 'BHCK0397': 'Interest-Bearing Balances in Foreign Offices, Edge and Agreement Subsidiaries and Ibfs',\n",
    " 'BHCK0395': 'Interest-Bearing Balances in U.S. Offices',\n",
    " 'BHCK0081': 'Noninterest-Bearing Balances and Currency and Coin'\n",
    "}\n",
    "var_list = [key for key, value in mdrm.items()]\n",
    "df = df[var_list]\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03b2191",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Setting a datadate column**\n",
    "\n",
    "---\n",
    "\n",
    "Use `pd.to_datetime(df['RSSD9999'])` to create a column named `datadate`. Use the format parameter to acknowledge the date format with year first, and day last (20190331):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ce372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a947d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['datadate'] = pd.to_datetime(df['RSSD9999'], format = '%Y%m%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77c090f",
   "metadata": {},
   "source": [
    "Use `agg` to check the date range of ` datadate`: do the minimum and maximum values make sense? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6faa7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['datadate'].agg(['min', 'max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758d175",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Eliminating rows that we don't need**\n",
    "\n",
    "Using `dropna`, eliminate rows from the data frame with missing values for `BHCK3210` (equity) `BHCK2170` (total assets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da4c15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['BHCK3210', 'BHCK2170'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f18d8",
   "metadata": {},
   "source": [
    "How many (or few) rows does the data frame have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a197a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bd2c71",
   "metadata": {},
   "source": [
    "Use `df.datadate.value_counts()` to check the number of firms per quarter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35abd9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.datadate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7412c557",
   "metadata": {},
   "source": [
    "The last quarter (`'2021-12-31'`) has few useful rows. \n",
    "\n",
    "Using `.loc`, eliminate rows from that quarter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34dd318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df.datadate != '2021-12-31']\n",
    "df.datadate.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c042b01a",
   "metadata": {},
   "source": [
    "Note, sometimes it is easier to use `df.datadate` instead of `df['datadate']`. But it is generally better to stick to the latter format."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757f60af",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Setting the index**\n",
    "\n",
    "---\n",
    "\n",
    "Set the index to `['RSSD9001', 'datadate']`: the bank identifier and the reporting date variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a2fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index(['RSSD9001', 'datadate'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544a4d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that it worked\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd5b31",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "**Selecting data from individual banks.**\n",
    "\n",
    "---\n",
    "\n",
    "Using the index to find data from CitiGroup, which has id: *1951350*, works even if you have a multi-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47c50a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#citi = df.loc[1951350]\n",
    "citi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b047538",
   "metadata": {},
   "source": [
    "How would you select data from CitiGroup (1951350) and Bank of America (*1073757*)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee29343",
   "metadata": {},
   "outputs": [],
   "source": [
    "citi_boa = df.loc[[1073757, 1951350]]\n",
    "citi_boa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd63b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "citi_boa.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c8d994f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Replacing values**\n",
    "\n",
    "---\n",
    "\n",
    "Note that `RSSD4087` (*Entity's World Wide Web Address*) is `'0'` in some rows. \n",
    "\n",
    "Mark these as missing values using the `replace` command, where you use Numpy's NaN (`np.NaN`) as the replacement value for '0':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335d1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RSSD4087'].replace('0', np.NaN, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663f572f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['RSSD4087']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5469774f",
   "metadata": {},
   "source": [
    "**Required**: Now do the same for all rows with zero values for *risk-weighted assets* `BHCAA223`. \n",
    "\n",
    "**Hint**: *risk-weighted assets* are floats, i.e. numbers, not text; whereas the WWW address was string `'0'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8aee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BHCAA223'].replace(0, np.NaN, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439bab1a",
   "metadata": {},
   "source": [
    "Check that it worked, the minimum value should be > zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e9fc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['BHCAA223'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7265588d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**How did bank liquidity change over recent quarters?**\n",
    "\n",
    "---\n",
    "\n",
    "In this part of the assignment you will calculate a liquidity ratio to measure trends in U.S. bank liquidity.\n",
    "\n",
    "Define `cash` as the sum of these items: `BHCK0081` , `BHCK0395`, `BHCK0397`, and `BHCK1773`. \n",
    "\n",
    "You can check the item names using the dictionary `mdrm`. For example: \n",
    "`mdrm['BHCK0081']` for '*Noninterest-Bearing Balances and Currency and Coin*'.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138b9df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cash'] =  df[['BHCK0081', 'BHCK0395', 'BHCK0397', 'BHCK1773']].sum(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcd6c95",
   "metadata": {},
   "source": [
    "**Question**: What if we did not specify `axis='columns'` in the previous command?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f41c98",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924a6e82",
   "metadata": {},
   "source": [
    "**Required**: Define `df['liq_ratio']` as the ratio of `cash` over total assets (`BHCK2170`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108e22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liq_ratio'] =  df['cash']/df['BHCK2170']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6660e460",
   "metadata": {},
   "source": [
    "**Question**: Is the data well-behaved, e.g. no outliers? \n",
    "\n",
    "Let's show the distribution of this variable using `hist()`. (See this [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.hist.html) for more on this command.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc2b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liq_ratio'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04734d3",
   "metadata": {},
   "source": [
    "To plot the trend in bank liquidity over recent quarters, we can \n",
    "\n",
    "- use the approach shown in [Session 5](https://martien.netlify.app/slides/session5/), using the `resample` command, where we 'resample' the data per quarter and then take the mean of `liq_ratio`. However, we are not really resampling, because the frequency of the data is quarterly already. Moreover, if we resample we need to reset the index and set it to `datadate` only: `df = df.reset_index().set_index('datadate')`.\n",
    "- Therefore, **it is better to group the data by `datadate`**, using `groupby`, then take the mean, and plot. In that case we do not need to reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e201e279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using resample - will throw an error, so I commented it out.\n",
    "# df['liq_ratio'].resample('Q').mean().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24354520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using groupby\n",
    "df['liq_ratio'].groupby('datadate').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a73310a",
   "metadata": {},
   "source": [
    "**Required**: Make the figure larger using `figsize=(8,6)` and add a meaningful title.\n",
    "\n",
    "See this [link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) for documentation on `plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe76ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['liq_ratio'].groupby('datadate').mean().plot(figsize=(8,6), title= 'U.S. bank liquidity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404eedbe",
   "metadata": {},
   "source": [
    "We can store the underlying data in a separate frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f00fdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lr = df['liq_ratio'].groupby('datadate').mean()\n",
    "df_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3f7002",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**How did bank capital ratios change over recent quarters?**\n",
    "\n",
    "---\n",
    "\n",
    "To answer this question we can rely on these two items: \n",
    "- `BHCA7206`: 'Tier 1 Risk-Based Capital Ratio'\n",
    "- `BHCA7204`: 'Tier 1 Leverage Capital Ratio'\n",
    "- `BHCA7205`: 'Total Risk-Based Capital Ratio'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db94bc0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[['BHCA7206', 'BHCA7204', 'BHCA7205']].groupby('datadate').mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b1e2bb",
   "metadata": {},
   "source": [
    "In early 2020 the Tier 1 ratio dropped faster than the leverage ratio. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d895b7",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question**: Can we improve the presentation of the graph by using the variable labels instead of the mnemonics?\n",
    "\n",
    "**Hint**: one way is use the `mdrm` dictionary to rename the columns `['BHCA7206', 'BHCA7204', 'BHCA7205']`. See this [link](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.rename.html) for documentation on `rename`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b5753f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfl = df[['BHCA7206', 'BHCA7204', 'BHCA7205']].groupby('datadate').mean()\n",
    "dfl.rename(columns = mdrm, inplace = True)\n",
    "dfl.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb479d2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "\n",
    "**Joining data and counting the number of BHCs per state**\n",
    "\n",
    "---\n",
    "\n",
    "We can use the column `RSSD9200` (*Abbreviated State Name*) to count the number of BHCs per state. I want you to use state names instead. There is a GitHub site that can help us with this: click [here](https://gist.github.com/JeffPaine/3083347). The site offers a dictionary, which we can convert into a data frame, and then join with our main data frame.\n",
    "\n",
    "Copy that dictionary and complete the function that converts it to a dictionary that we can merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08522a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_names():\n",
    "    states = {'AK': 'Alaska', 'AL': 'Alabama', 'AR': 'Arkansas', 'AZ': 'Arizona', 'CA': 'California', 'CO': 'Colorado', 'CT': 'Connecticut', 'DC': 'District of Columbia', 'DE': 'Delaware', 'FL': 'Florida', 'GA': 'Georgia', 'HI': 'Hawaii', 'IA': 'Iowa', 'ID': 'Idaho', 'IL': 'Illinois', 'IN': 'Indiana', 'KS': 'Kansas', 'KY': 'Kentucky', 'LA': 'Louisiana', 'MA': 'Massachusetts', 'MD': 'Maryland', 'ME': 'Maine', 'MI': 'Michigan', 'MN': 'Minnesota', 'MO': 'Missouri', 'MS': 'Mississippi', 'MT': 'Montana', 'NC': 'North Carolina', 'ND': 'North Dakota', 'NE': 'Nebraska', 'NH': 'New Hampshire', 'NJ': 'New Jersey', 'NM': 'New Mexico', 'NV': 'Nevada', 'NY': 'New York', 'OH': 'Ohio', 'OK': 'Oklahoma', 'OR': 'Oregon', 'PA': 'Pennsylvania', 'RI': 'Rhode Island', 'SC': 'South Carolina', 'SD': 'South Dakota', 'TN': 'Tennessee', 'TX': 'Texas', 'UT': 'Utah', 'VA': 'Virginia', 'VT': 'Vermont', 'WA': 'Washington', 'WI': 'Wisconsin', 'WV': 'West Virginia', 'WY': 'Wyoming'}\n",
    "    states = pd.DataFrame.from_dict(states, orient ='index', columns=['State name'])\n",
    "    # The index of this data frame has no name, so we should name the index:\n",
    "    states.index.name='RSSD9200'\n",
    "    return states\n",
    "\n",
    "states = state_names()\n",
    "states.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0a69b1",
   "metadata": {},
   "source": [
    "We can now join straight away, without needing to set a key for the left-hand data frame (!)\n",
    "\n",
    "The only thing we need to do is to specify the relevant key column name from the left-hand data frame: '`RSSD9200`'. The advantage of this approach is that we do not need to set and reset the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657cedc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(states, on='RSSD9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605caa3e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Question**: What is wrong with the command below if we want to know the number of banks in our sample for a given year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82b27ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('State name')['RSSD9010'].count().head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6a66ef",
   "metadata": {},
   "source": [
    "**Required**: We can do better, by selecting a subset of the data: `df.loc[df['RSSD9999']==20210630, :]` and then apply the `groupby` statement from the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943cfbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfc = df.loc[df['RSSD9999']==20210630, :].groupby('State name')['RSSD9010'].count()\n",
    "dfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe3b649",
   "metadata": {},
   "source": [
    "**Bonus question**: How to turn the data from `dfc`  into a bar-plot with figure size (10 x 6) and title 'BHCs' ?\n",
    "\n",
    "See this [link](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.html) for documentation on `plot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ed0f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.sort_values(ascending = False).plot(kind='bar', figsize=(12,6), title='BHCs' )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
